# Virtual-Mouse-OpenCV
VMouSE-MSR
# ğŸ–±ï¸ Virtual Mouse using Python & OpenCV

This project is a **gesture-controlled virtual mouse** built with **Python, OpenCV, MediaPipe, and PyAutoGUI**.  
It uses hand-tracking to allow users to perform **mouse actions** such as cursor movement, left/right click, drag and drop, zoom, scroll, and area selection â€“ all without touching a physical mouse.

---

## ğŸš€ Features
- **Cursor Movement** â€“ Control your mouse pointer with hand gestures.
- **Left and Right Click** â€“ Single and right-click gestures with specific finger poses.
- **Drag & Drop** â€“ Use pinch gestures for smooth dragging.
- **Scroll Up & Down** â€“ Scroll using two-finger gestures.
- **Zoom In/Out** â€“ Perform zoom gestures (Ctrl + +/-).
- **Area Selection** â€“ Select an area using an index-finger double-click gesture.
- **Focus Mode** â€“ Pauses cursor movement when an open palm is detected.
- **Smooth Cursor** â€“ Reduced jitter with interpolation-based movement.
- **Cross-platform Support** â€“ Works on Windows, macOS, and Linux.

---

## ğŸ› ï¸ Tech Stack
- **Python 3.8+**
- [OpenCV](https://opencv.org/)
- [MediaPipe](https://developers.google.com/mediapipe)
- [PyAutoGUI](https://pyautogui.readthedocs.io/en/latest/)
- NumPy
- asyncio & time libraries

---

## ğŸ“¦ Installation

### **1. Clone the Repository**
```bash
git clone https://github.com/malrajusuhitha/virtual-mouse-opencv.git
cd virtual-mouse-opencv
```
### **2.Install Dependencies**
```bash
pip install opencv-python mediapipe numpy pyautogui
```
## â–¶ï¸How to Run
1.Connect your webcam.

2.Run the script:
```bash
python virtual_mouse.py
```
3.A window named "Virtual Mouse" will open.

4.Use your hand gestures to control the cursor:
Pinch (Index + Thumb) â€“ Drag & drop.
Thumb open (others closed) â€“ Left click.
Pinky up â€“ Right click.
Two fingers up/down â€“ Scroll.
Zoom gesture â€“ Zoom in/out (Ctrl + +/-).
Index double click â€“ Select area.
Press q to quit.

## ğŸ“‚ Project Structure
```csharp

virtual-mouse-opencv/
â”‚-- cursor.py        # Main program file
â”‚-- README.md               # Project documentation
```

## ğŸ“Œ Notes
1.The script runs at 30 FPS and uses MediaPipe for accurate hand landmark detection.

2.Use a well-lit environment for better hand tracking.

3.Cursor smoothness and gesture sensitivity can be adjusted in the script (smooth_factor, zoom_threshold, etc.).

## ğŸ™Œ Contributing
Feel free to fork this repo, raise issues, and submit pull requests.

## ğŸ‘¤ Author
Malraju Suhitha Rao
